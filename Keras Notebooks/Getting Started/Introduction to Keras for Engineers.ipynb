{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Keras for Engineers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Are you a machine learning engineer looking to use Keras to ship deep-learning powered features in real products? This guide will\n",
    "server as your first introduction to core Keras API concepts.\n",
    "\n",
    "In this guide, you will learn how to:\n",
    "\n",
    "* Prepare your data before training a model (by turning it into either NumPy arrays or tf.data.Dataset objects)\n",
    "* Do data preprocessing, for instance feature normalization or vocabulary indexing.\n",
    "* Build a model that turns your data into useful predictions, useing the Keras Functional API.\n",
    "* Train your model with the built-in Keras fit() function, while being mindful of checkpointing, metrics monitoring, and fault tolerance\n",
    "* Evaluate your model on a test dataset and how to use it for inference on new data.\n",
    "* Customize what fit() does, for instance to build a GAN.\n",
    "* Speed up training by leveraging multiple GPUs.\n",
    "* Refine your model through hyperparameter tuning.\n",
    "\n",
    "As the end of this guide, you will get pointers to end-to-end examples to solidify these concepts:\n",
    "\n",
    "* Image classification\n",
    "* Text classification\n",
    "* Credit card fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & preprocessing\n",
    "\n",
    "Neural networks don't process raw data, like text files, encoded JPEG image files, or CSV files. They process vectorized & standardized representations.\n",
    "\n",
    "* Text files need to be read into string tensors, then split into words. Finally, the words need to be indexed and turned into integer tensors.\n",
    "* Images need to be read and decoded into integer tensors, then converted to floating point and normalized to small values (usually between 0 and 1).\n",
    "* CSV data needs to be parsed, with numercial features converted to floating point tensors and categorical features indexed and converted to integer tensors. Then each feature typically needs to be normalized to zero-mean and unit-variance.\n",
    "* Etc.\n",
    "\n",
    "Let's start with data loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Keras models accept three types of inputs:\n",
    "\n",
    "* NumPy arrays, just like Scikit-learn and many other Python-based libraries. This is a good option if your data fits in memory.\n",
    "* Tensorflow Dataset Objects. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed file system.\n",
    "* Python generators that yield batches of data (such as custom subclasses of the keras.utils.Sequence class).\n",
    "\n",
    "Before you start training a model, you will need to make your data available as one of these formants. If you have a large dataset and you are training on GPU(s), consider using Dataset objects, since they will take care of performance-critical details, such as:\n",
    "\n",
    "* Asynchronously preprocessing your data on CPU while your GPU is busy, and buffering it into a queue.\n",
    "* Prefetching data on GPU memory so it's immediately available when the GPU has finished processing the previous batch, so you can reach full GPU utilization.\n",
    "\n",
    "Kerras features a range of utilities to help you turn raw data on disk into a Dataset:\n",
    "\n",
    "* tf.keras.preprocessing.image_dataset_from_directory turns image files sorted into class-specific folders into a labeled dataset of image tensors.\n",
    "* tf.keras.preprocessing.text_dataset_from_directory does the same for text files.\n",
    "\n",
    "In addition, the TensorFlow tf.data includes other similar utilities, such as tf.data.experimental.make_csv_dataset to load structured data from CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: obtaining a labeled dataset from image files on disk\n",
    "\n",
    "Supposed you have image files sorted by class in different folder, like this:\n",
    "\n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_image_1.jpg\n",
    "......a_image_2.jpg\n",
    "...class_b/\n",
    "......b_image_1.jpg\n",
    "......b_image_2.jpg\n",
    "\n",
    "Then you can do:\n",
    "\"\"\"\n",
    "\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\"PATH_TO_MAIN_DIRECTORY\", batch_size=64, image_size=(200,200))\n",
    "\n",
    "for data, labels in dataset:\n",
    "    print(data.shape)   # (64, 200, 200, 3)\n",
    "    print(data.dtype)   # float32\n",
    "    print(labels.shape) # (64, )\n",
    "    print(labels.dtype) # int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label of a sample is the rank of its folder in alphanumeric order. Naturally, this can also be configured explicitly\n",
    "by passing, e.g. class_names = ['class_a', 'class_b'], in which cases label 0 will be class_a and 1 will be class_b.\n",
    "\n",
    "**Example: obtaining a labeled dataset from text files on disk**\n",
    "\n",
    "Likewise for text: if you have .txt documents sorted by class in different folder, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = keras.preprocessing.text_dataset_from_directory('path/to/main_directory', batch_size=64)\n",
    "\n",
    "# For demonstration, iterate over the batches yielded by the dataset.\n",
    "for data, labels in dataset:\n",
    "    print(data.shape)   # (64, )\n",
    "    print(data.dtype)   # string\n",
    "    print(labels.shape) # (64, )\n",
    "    print(labels.dtype) # int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing with Keras\n",
    "\n",
    "Once your data is in the form of string/int/float NumpPy arrays, or a Dataset object (or Python generator) that yields batches of\n",
    "string/int/float tensors, it is time to **preprocess** the data. This can mean:\n",
    "\n",
    " * Tokenization of string data, followed by token indexing\n",
    " * Feature normalization\n",
    " * Rescaling the data to small values (in general, input values to a neural network should be close to zero --\n",
    "  typically we expect either data with zero-mean and unit-variance, or data in the [0, 1] range.)\n",
    "\n",
    "#### The ideal machine learning model is end-to-end\n",
    "\n",
    "In genreal, you should seek to do data preprocessing **as part of your model** as much as possible, not via an external data\n",
    "preprocessing pipeline. That's because external data preprocessing makes your models less p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0bcce3b9f8d091a44021cb8a03985b3e8b40c6ce23beeff54c946abf41b93cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
